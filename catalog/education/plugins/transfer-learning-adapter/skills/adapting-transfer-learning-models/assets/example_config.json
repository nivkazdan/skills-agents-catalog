{
  "_comment": "Example configuration for transfer learning adaptation.",
  "model_name": "bert-base-uncased",
  "_comment": "Pre-trained model to adapt.  Choose from Hugging Face model hub.",
  "dataset_name": "glue",
  "_comment": "Dataset to fine-tune on.  Choose from Hugging Face datasets or specify a local path.",
  "dataset_subset": "mrpc",
  "_comment": "Specific subset of the dataset to use (if applicable).",
  "train_file": null,
  "_comment": "Optional path to a custom training data file.  Overrides dataset_name and dataset_subset if provided.",
  "validation_file": null,
  "_comment": "Optional path to a custom validation data file.  Overrides dataset_name and dataset_subset if provided.",
  "output_dir": "./adapted_model",
  "_comment": "Directory to save the adapted model and training logs.",
  "num_epochs": 3,
  "_comment": "Number of training epochs.",
  "learning_rate": 2e-5,
  "_comment": "Learning rate for the AdamW optimizer.",
  "batch_size": 32,
  "_comment": "Batch size for training and evaluation.",
  "weight_decay": 0.01,
  "_comment": "Weight decay for regularization.",
  "seed": 42,
  "_comment": "Random seed for reproducibility.",
  "max_length": 128,
  "_comment": "Maximum sequence length for input tokens.  Truncate or pad sequences as needed.",
  "task_name": "text_classification",
  "_comment": "Type of task for which the model is being adapted. Options: text_classification, token_classification, question_answering, sequence_to_sequence.",
  "metric": "accuracy",
  "_comment": "Primary metric to evaluate performance. Options depend on the task. Common examples: accuracy, f1, rouge, bleu.",
  "gradient_accumulation_steps": 1,
  "_comment": "Number of steps to accumulate gradients before performing a backward/update pass.",
  "fp16": true,
  "_comment": "Whether to use 16-bit floating point precision (Mixed Precision Training).",
  "evaluation_strategy": "epoch",
  "_comment": "Evaluation strategy to adopt during training. Options: steps, epoch",
  "save_strategy": "epoch",
  "_comment": "Save strategy to adopt during training. Options: steps, epoch",
  "logging_steps": 100,
  "_comment": "Log every X updates steps.",
  "push_to_hub": false,
  "_comment": "Whether to push the adapted model to the Hugging Face Hub.",
  "hub_model_id": null,
  "_comment": "The name of the repository to keep in sync with the local adapted model. It can be a path to an existing repository on the Hub or a new one. Overrides the repository id in the Trainer's config.",
  "hub_token": null,
  "_comment": "The token to use when pushing the adapted model to the Hub.",
  "device": "cuda",
  "_comment": "Device (cpu, cuda) on which the code should be run.",
  "tokenizer_name": null,
  "_comment": "Optional tokenizer name to use. If not provided, the tokenizer associated with the model_name will be used.",
  "do_train": true,
  "_comment": "Whether to perform training.",
  "do_eval": true,
  "_comment": "Whether to perform evaluation."
}